---
layout:     post
title:      大数据集群安装
subtitle:   kafka
date:       2018-7-27
author:     张忠欣
header-img: img/post-bg-universe.jpg
catalog: true
tags:
    - 大数据
---


## 简介

    Kafka is a distributed,partitioned,replicated commit logservice。它提供了类似于
JMS的特性，但是在设计实现上完全不同，此外它并不是JMS规范的实现。kafka对消息保存时根据Topic
进行归类，发送消息者成为Producer,消息接受者成为Consumer,此外kafka集群有多个kafka实例组成，
每个实例(server)成为broker。无论是kafka集群，还是producer和consumer都依赖于zookeeper来
保证系统可用性集群保存一些meta信息。

## 正文

kafka 集群是由 scala 编写，所以建议安装scala 来自己编译kafka(不安装scala 也可以，直接去下载现成的包即可)

安装kafka 集群：
```objc
1、下载 scala-2.11.8.tgz 包 上传到hadoop01 的/data/workdir 目录下。
2、对 scala-2.11.8.tgz 进行解压缩：tar -zxvf scala-2.11.8.tgz。
3、对scala目录进行重命名：mv scala-2.11.8 scala
4、配置scala相关的环境变量
vi ~/.bash_profile
export SCALA_HOME=/data/workdir/scala
export PATH=$SCALA_HOME/bin
source ~/.bash_profile
5、查看scala是否安装成功：scala -version
6、按照上述步骤在 hadoop02 和 hadoop03 机器上都安装好 scala。使用scp将 scala 和 ~/.bash_profile 拷贝到 hadoop02 和 hadoop03 上即可。

安装kafka 包

1、将课程提供的kafka_2.9.2-0.8.1.tgz使用WinSCP拷贝到spark1的/usr/local目录下
2、对 kafka_2.11-0.9.0.0.tgz 进行解压缩：tar -zxvf kafka_2.11-0.9.0.0.tgz
3、对kafka目录进行改名：mv kafka_2.9.2-0.8.1 kafka
4、配置kafka
vi /data/workdir/kafka/config/server.properties
broker.id：依次增长的整数，0、1、2、3、4，集群中Broker的唯一id
zookeeper.connect=192.168.1.107:2181,192.168.1.108:2181,192.168.1.109:2181

5、安装slf4j
将下载的 slf4j-1.7.6.zip上传到/da'ta/workdir 目录下
unzip slf4j-1.7.6.zip
把slf4j中的slf4j-nop-1.7.6.jar复制到kafka的libs目录下面

搭建kafka 集群：
1、按照上述步骤在 hadoiop02 和 hadoop03 分别安装 kafka。用scp把kafka拷贝到 hadoop02 和 hadoop03 行即可。
2、唯一区别的，就是server.properties中的broker.id，要设置为1和2

启动kafka 集群
1、在三台机器上分别执行以下命令：bin/kafka-server-start.sh config/server.properties
2、解决kafka Unrecognized VM option 'UseCompressedOops'问题
vi bin/kafka-run-class.sh
if [ -z "$KAFKA_JVM_PERFORMANCE_OPTS" ]; then
  KAFKA_JVM_PERFORMANCE_OPTS="-server  -XX:+UseCompressedOops -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+CMSScavengeBeforeRemark -XX:+DisableExplicitGC -Djava.awt.headless=true"
fi

去掉-XX:+UseCompressedOops即可

3、使用jps检查启动是否成功

测试kafka 集群
使用基本命令检查kafka是否搭建成功
bin/kafka-topics.sh --zookeeper 192.168.1.107:2181,192.168.1.108:2181,192.168.1.109:2181 --topic TestTopic --replication-factor 1 --partitions 1 --create
bin/kafka-console-producer.sh --broker-list 192.168.1.107:9092,192.168.1.108:9092,192.168.1.109:9092 --topic TestTopic
bin/kafka-console-consumer.sh --zookeeper 192.168.1.107:2181,192.168.1.108:2181,192.168.1.109:2181 --topic TestTopic --from-beginning

```

学到这里 是不是感觉kafka 也挺简单??? 咦,,, 普通使用 只要 producer 和 consumer 就够了，但是kafka 的主副本备份 是有数据安全问题的，尤其使用kafka
低级api,虽然灵活，但是 offset 的安全很难保证,

那么有好的改进方法么? 

方法肯定是有的

接下来 欢迎继续关注我的博客 我后续会推出 我对kafka数据消费安全方面的浅见理解



