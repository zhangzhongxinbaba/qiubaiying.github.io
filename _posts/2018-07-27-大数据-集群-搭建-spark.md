---
layout:     post
title:      大数据集群搭建
subtitle:   spark
date:       2018-7-27
author:     zhangzhongxin
header-img: img/post-bg-universe.jpg
catalog: true
tags:
    - 大数据
---


## 前言
spark 对于我个人呢,刚接触一年多，接触spark 之前 多数是玩MR，感觉hadoop 生态的东西很牛X，但是呢，mr 的计算中间结果要存储
到磁盘上，大量的读写磁盘，会导致计算性能比较慢，而spark 则是把计算的中间结果全都保留在内存中，计算速度相当可观，spark还在
job 划分，stage 划分，rdd 依赖上做了很多的优化，即使计算几点宕机，依然不影响计算。但是在我个人对hadoop 的 spark 的学习
中，我仍然固执的喜欢hadoop，怎么说呢 我个人认为spark 的出现完全是抄袭hadoop，思想基本没变，只是把hadoop 的mr 做了很多
优化而已。

重要的是hadoop 3.0 已经快要发布，据说 Hadoop 3.0 一改往日大量依赖磁盘的陋习，在内存越来越便宜的时代，也要开始充分利用内存，
mr 采用 内存+io+磁盘 的设计方式，号称比spark 快十倍 (虽然我很喜欢hadoop，但是仍然感觉快十倍 是在吹牛叉) 😄

吐槽一下: 

hadooop 3.0 在发布新特性的时候，说改进hdfs 为通过最近black块计算，根据最近计算原则，本地black块，加入到内存，先
计算，通过IO，共享内存计算区域，最后快速形成计算结果。

槽点：hadoop 2.x 版本已经可以通过参数来配置绕过hdfs 服务端口，直接读取本地文件，直接加载到内存了，不了解为什么这还要被强调为新特性，
可能是我太浅显把

## 正文
spark 搭建
```objc
1. 首先我们去spark 官网下载spark 2.2.0 的源码，然后手动将其编译为 cdh-5.7.0 版本，编译方法：详见spark 官网
2. 解压缩spark包：tar zxvf spark-2.2.0-bin-hadoop2.6.tgz。
3. 更改spark目录名：mv spark-2.2.0-bin-hadoop2.6.tgz spark
4. 设置spark环境变量
vi ~/.bash_profile
export SPARK_HOME=/data/workdir/spark
export PATH=$SPARK_HOME/bin
export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib
source .bashrc

修改spark-env.sh

1、cd /data/workdir/spark/conf
2、cp spark-env.sh.template spark-env.sh
3、vi spark-env.sh
export JAVA_HOME=/data/workdir/latest
export SCALA_HOME=/data/workdir/scala
export SPARK_MASTER_IP=192.168.1.107
export SPARK_WORKER_MEMORY=1g
export HADOOP_CONF_DIR=/data/workdir/hadoop/etc/hadoop

修改slave 
hadoop01
hadoop02
hadoop03

安装spark 
在另外两个节点进行一模一样的配置，使用scp将 hadoop01 和 ~/.bash_profile 拷贝到 hadoop02 和 hadoop03 即可。

启动spark：
1、在spark目录下的sbin目录
2、执行./start-all.sh
3、使用jsp和8080端口可以检查集群是否启动成功
4、进入spark-shell查看是否正常
```

## 个人对spark 应用的理解
spark 常用的 主要是 spark-core spark-sql spark-streaming，对批处理 个人建议用spark-core，虽说spark 官网强调spark-sql 专门为批处理应运而生，
而且sparksql 支持各种sql 语法，但是呢 spark-sql 最终还是要转化为 spark-core 来处理，就好比 hive 依赖 mr 来执行，而且据百度的大牛们研究源码
认为，sparksql 很吃内存(相对于 spark-core)

对于我自己，如果是批处理我更喜欢 hadoop 的mr 或者hive ，因为既然已经是批处理，业务肯定是分析和挖掘类的不需要低延时的场景，mr 虽然慢，但是稳定，
而且很节省资源（老板请你来是来解决技术问题的，不是 一门要资源的），对于spark 的应用，我较多的使用spark-streaming 做流处理

说说spark-streaming

spark-streaming 稍微有那么点延时的批处理，不过如果是strom 虽然是实时的逐条的处理，但是举个例子：

eg：每秒来 1000 条数据，strom 每秒只能处理 20 条，虽然实时，但是 全都挤压到一起了

eg：每秒来 1000 条数据，strom 每2秒能处理 5000 条，虽然名义上是批处理，但是实时性比strom 还要好

spark-streaming 虽然很快，但是快是有代价的，在每一批次的处理中，会有数据安全问题，后面的博客 我会详细介绍

关于与spark 类似的flink

阿里 美团等大厂已经开始推广flink，相信未来绝对可以从spark嘴里抢走很多肉，相比于spark，flink更加稳定，具体关于spark 和flink 的学习笔记我会在后期更新

欢迎关注！！！
